{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9e25f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV, cross_val_predict\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, clone\n",
    "\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from boruta import BorutaPy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Create artifacts folder if not exists\n",
    "os.makedirs(\"../artifacts\", exist_ok=True)\n",
    "\n",
    "# ------------------------\n",
    "# Boruta wrapper\n",
    "# ------------------------\n",
    "\n",
    "class BorutaSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, estimator=None, n_estimators=100, verbose=0, random_state=None):\n",
    "        self.estimator = estimator\n",
    "        self.n_estimators = n_estimators\n",
    "        self.verbose = verbose\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X_arr = np.asarray(X)\n",
    "        y_arr = np.asarray(y)\n",
    "        if self.estimator is None:\n",
    "            base_est = RandomForestClassifier(n_estimators=self.n_estimators,\n",
    "                                              n_jobs=-1, random_state=self.random_state)\n",
    "        else:\n",
    "            base_est = clone(self.estimator)\n",
    "        self.boruta_ = BorutaPy(base_est, n_estimators=self.n_estimators, verbose=self.verbose, random_state=self.random_state)\n",
    "        self.boruta_.fit(X_arr, y_arr)\n",
    "        self.support_ = self.boruta_.support_.copy()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_arr = np.asarray(X)\n",
    "        if not hasattr(self, \"support_\"):\n",
    "            raise RuntimeError(\"BorutaSelector must be fitted before transform()\")\n",
    "        if np.sum(self.support_) == 0:\n",
    "            return X_arr\n",
    "        return X_arr[:, self.support_]\n",
    "\n",
    "    def get_support(self):\n",
    "        return getattr(self, \"support_\", None)\n",
    "\n",
    "# ------------------------\n",
    "# Helper function for evaluation\n",
    "# ------------------------\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def evaluate_per_fold(pipeline, X, y, cv):\n",
    "    fold_accuracies = []\n",
    "    fold_macro_f1 = []\n",
    "    fold_per_class_f1 = []\n",
    "\n",
    "    for fold_idx, (train_idx, test_idx) in enumerate(cv.split(X, y)):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        model = clone(pipeline)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        macro = f1_score(y_test, y_pred, average=\"macro\")\n",
    "        per_class = f1_score(y_test, y_pred, average=None)\n",
    "\n",
    "        fold_accuracies.append(acc)\n",
    "        fold_macro_f1.append(macro)\n",
    "        fold_per_class_f1.append(per_class)\n",
    "\n",
    "        print(f\"[Fold {fold_idx+1}] acc={acc:.4f}, macroF1={macro:.4f}, per-class={per_class}\")\n",
    "\n",
    "    fold_per_class_f1 = np.array(fold_per_class_f1)\n",
    "\n",
    "    results = {\n",
    "        \"accuracy_mean\": np.mean(fold_accuracies),\n",
    "        \"accuracy_sd\": np.std(fold_accuracies),\n",
    "        \"macro_f1_mean\": np.mean(fold_macro_f1),\n",
    "        \"macro_f1_sd\": np.std(fold_macro_f1),\n",
    "        \"class_f1_means\": np.mean(fold_per_class_f1, axis=0),\n",
    "        \"class_f1_sds\": np.std(fold_per_class_f1, axis=0)\n",
    "    }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8fc1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "# Load Data\n",
    "# ------------------------\n",
    "\n",
    "data_path = \"../data/preprocessed/head_modifiers_pairs.csv\"\n",
    "if not os.path.exists(data_path):\n",
    "    raise FileNotFoundError(f\"Preprocessed CSV not found at {data_path}\")\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "print(\"Loaded data:\", df.shape)\n",
    "\n",
    "# Encode target labels\n",
    "\n",
    "le_ezafe = LabelEncoder()\n",
    "df['ezafe_label_enc'] = le_ezafe.fit_transform(df['ezafe_label'])\n",
    "\n",
    "le_combined = LabelEncoder()\n",
    "df['combined_label'] = df['ezafe_label_enc'].astype(str) + \"_\" + df['position'].astype(str)\n",
    "df['combined_label_enc'] = le_combined.fit_transform(df['combined_label'])\n",
    "\n",
    "joblib.dump(le_ezafe, \"../artifacts/le_ezafe.joblib\")\n",
    "joblib.dump(le_combined, \"../artifacts/le_combined.joblib\")\n",
    "\n",
    "# Features and targets\n",
    "\n",
    "drop_cols = ['nominal_head_form', 'modifier_form', 'ezafe_label', 'position',\n",
    "             'combined_label', 'ezafe_label_enc', 'combined_label_enc']\n",
    "X = df.drop(columns=[c for c in drop_cols if c in df.columns])\n",
    "y_comb = df['combined_label_enc'].values\n",
    "y_ezafe = df['ezafe_label_enc'].values\n",
    "y_pos = df['position'].astype(int).values\n",
    "\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numeric_cols = [c for c in X.columns if c not in categorical_cols]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9794a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "# Define Pipeline and RandomizedSearchCV\n",
    "# ------------------------\n",
    "\n",
    "boruta_base_estimator = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    class_weight='balanced',\n",
    "    n_jobs=-1,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "ros = RandomOverSampler(random_state=RANDOM_STATE)\n",
    "\n",
    "pipeline = ImbPipeline([\n",
    "    ('pre', preprocessor),\n",
    "    ('ros', ros),\n",
    "    ('boruta', BorutaSelector(estimator=boruta_base_estimator, n_estimators=100, verbose=0, random_state=RANDOM_STATE)),\n",
    "    ('clf', RandomForestClassifier(n_jobs=-1, random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "param_dist = {\n",
    "    'clf__n_estimators': [100, 200, 300],\n",
    "    'clf__max_depth': [None, 10, 20],\n",
    "    'clf__min_samples_split': [2, 5],\n",
    "    'clf__class_weight': [\n",
    "        {0:1,1:1,2:1,3:1},\n",
    "        {0:1,1:1,2:1,3:3},\n",
    "        {0:1,1:1,2:1,3:5},\n",
    "        {0:1,1:1,2:1,3:10}\n",
    "    ]\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "random_search = RandomizedSearchCV(\n",
    "    pipeline, param_distributions=param_dist,\n",
    "    n_iter=10, cv=cv, scoring='f1_weighted',\n",
    "    random_state=RANDOM_STATE, verbose=2, n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ef73b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "# Fit RandomizedSearchCV\n",
    "# ------------------------\n",
    "\n",
    "print(\"Starting RandomizedSearchCV (this may take a while)...\")\n",
    "random_search.fit(X, y_comb)\n",
    "print(\"Best parameters:\", random_search.best_params_)\n",
    "best_pipeline = random_search.best_estimator_\n",
    "joblib.dump(best_pipeline, \"../artifacts/best_pipeline_combined.joblib\")\n",
    "print(\"Saved best pipeline.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22fefdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "# Feature Selection and Evaluation\n",
    "# ------------------------\n",
    "\n",
    "pre = best_pipeline.named_steps['pre']\n",
    "try:\n",
    "    pre_feature_names = pre.get_feature_names_out()\n",
    "except Exception:\n",
    "    pre_feature_names = np.array(X.columns.tolist())\n",
    "\n",
    "boruta_mask = best_pipeline.named_steps['boruta'].get_support()\n",
    "if boruta_mask is not None:\n",
    "    selected_features = list(np.array(pre_feature_names)[boruta_mask])\n",
    "else:\n",
    "    selected_features = list(pre_feature_names)\n",
    "\n",
    "joblib.dump(selected_features, \"../artifacts/selected_feature_names.joblib\")\n",
    "print(\"Selected features saved:\", len(selected_features))\n",
    "\n",
    "print(\"\\nRunning per-fold evaluation...\")\n",
    "results = evaluate_per_fold(best_pipeline, X, y_comb, cv)\n",
    "print(\"Cross-validated results:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c452d71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "# Cell 5 (continued): Feature Selection\n",
    "# ------------------------\n",
    "if boruta_mask is not None:\n",
    "    selected_features = list(np.array(pre_feature_names)[boruta_mask])\n",
    "else:\n",
    "    selected_features = list(pre_feature_names)\n",
    "\n",
    "joblib.dump(selected_features, \"../artifacts/selected_feature_names.joblib\")\n",
    "print(\"Selected features saved:\", len(selected_features))\n",
    "\n",
    "# ------------------------\n",
    "# Cell 6: Two-stage evaluation (ezafe & position)\n",
    "# ------------------------\n",
    "# Recreate a fresh pipeline template with best classifier params\n",
    "clf_params = {k.replace('clf__', ''): v for k, v in random_search.best_params_.items() if k.startswith('clf__')}\n",
    "\n",
    "pipeline_for_cv = ImbPipeline([\n",
    "    ('pre', preprocessor),\n",
    "    ('ros', RandomOverSampler(random_state=RANDOM_STATE)),\n",
    "    ('boruta', BorutaSelector(estimator=clone(boruta_base_estimator), n_estimators=100, verbose=0, random_state=RANDOM_STATE)),\n",
    "    ('clf', RandomForestClassifier(random_state=RANDOM_STATE, n_jobs=-1, **clf_params))\n",
    "])\n",
    "\n",
    "# --- Stage 1: Ezafe ---\n",
    "print(\"\\n=== Two-stage CV: Ezafe ===\")\n",
    "y_pred_ezafe = cross_val_predict(pipeline_for_cv, X, y_ezafe, cv=cv, n_jobs=-1)\n",
    "ezafe_results = evaluate_per_fold(pipeline_for_cv, X, y_ezafe, cv)\n",
    "print(\"Ezafe per-fold results:\", ezafe_results)\n",
    "\n",
    "# --- Stage 2: Position ---\n",
    "print(\"\\n=== Two-stage CV: Position ===\")\n",
    "y_pred_pos = cross_val_predict(pipeline_for_cv, X, y_pos, cv=cv, n_jobs=-1)\n",
    "position_results = evaluate_per_fold(pipeline_for_cv, X, y_pos, cv)\n",
    "print(\"Position per-fold results:\", position_results)\n",
    "\n",
    "# --- Stage 3: Combined labels\n",
    "y_pred_combined = [f\"{e}_{p}\" for e, p in zip(y_pred_ezafe, y_pred_pos)]\n",
    "y_true_combined = df['ezafe_label_enc'].astype(str) + \"_\" + df['position'].astype(str)\n",
    "\n",
    "mapping = {lab: idx for idx, lab in enumerate(le_combined.classes_)}\n",
    "y_pred_encoded = np.array([mapping.get(lbl, -1) for lbl in y_pred_combined])\n",
    "y_true_encoded = np.array([mapping[lbl] for lbl in y_true_combined])\n",
    "\n",
    "valid_idx = (y_pred_encoded != -1)\n",
    "y_pred_encoded = y_pred_encoded[valid_idx]\n",
    "y_true_encoded = y_true_encoded[valid_idx]\n",
    "\n",
    "label_mapping = {\n",
    "    \"0_1\": \"No ezafe & Head Initial\",\n",
    "    \"0_2\": \"No ezafe & Head Final\",\n",
    "    \"1_1\": \"With ezafe & Head Initial\",\n",
    "    \"1_2\": \"With ezafe & Head Final\"\n",
    "}\n",
    "\n",
    "unique_true_encoded = np.unique(y_true_encoded)\n",
    "decoded_class_labels = [le_combined.inverse_transform([i])[0] for i in unique_true_encoded]\n",
    "readable_labels = [label_mapping.get(label, label) for label in decoded_class_labels]\n",
    "\n",
    "print(\"\\nTwo-Stage Classification Report (RF-5-fold CV):\")\n",
    "print(classification_report(y_true_encoded, y_pred_encoded, target_names=readable_labels, digits=4))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true_encoded, y_pred_encoded, labels=unique_true_encoded)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap=\"cividis\",\n",
    "            xticklabels=readable_labels, yticklabels=readable_labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Composite Confusion Matrix (5-fold CV)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
